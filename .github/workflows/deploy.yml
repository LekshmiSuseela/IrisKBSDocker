name: CI/CD Pipeline for IRIS API
on:
  push:
    branches: [main]
env:
  IMAGE_NAME: iris-api
  GAR_LOCATION: us-central1-docker.pkg.dev/mlops-474118/iris-api-repo/iris-api
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      # Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # Authenticate to GCP
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Setup gcloud CLI
      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      # Install GKE Auth Plugin
      - name: Install GKE Auth Plugin
        run: |
          gcloud components update --quiet
          gcloud components install gke-gcloud-auth-plugin --quiet
          export USE_GKE_GCLOUD_AUTH_PLUGIN=True

      # Get GKE credentials
      - name: Get GKE Credentials
        run: |
          gcloud container clusters get-credentials ${{ secrets.GKE_CLUSTER }} \
            --zone ${{ secrets.GKE_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }}

      # Setup Python
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Install Python dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Install Metrics Server
      - name: Install Metrics Server
        run: |
          kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
          kubectl wait --for=condition=available --timeout=120s deployment/metrics-server -n kube-system

      # Run poisoned training with MLFlow
      - name: Run poisoned training (MLFlow)
        run: |
          export MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}
          python train.py

      # Build and push Docker image
      - name: Build & push Docker image
        run: |
          gcloud auth configure-docker ${{ secrets.GCP_REGION }}-docker.pkg.dev --quiet
          docker build -t $GAR_LOCATION:${{ github.sha }} .
          docker push $GAR_LOCATION:${{ github.sha }}

      # Deploy to GKE and patch resources
      - name: Deploy to GKE with resources
        run: |
          kubectl set image deployment/iris-api iris-api=$GAR_LOCATION:${{ github.sha }} --namespace=default
          kubectl rollout status deployment/iris-api --namespace=default

          # Patch deployment to add CPU/memory requests and limits
          kubectl patch deployment iris-api -n default -p '{
            "spec": {
              "template": {
                "spec": {
                  "containers": [{
                    "name": "iris-api",
                    "resources": {
                      "requests": {"cpu": "500m","memory": "128Mi"},
                      "limits": {"cpu": "1","memory": "256Mi"}
                    }
                  }]
                }
              }
            }
          }'
          echo "‚úÖ Resources applied to iris-api"

      # Apply Horizontal Pod Autoscaler
      - name: Apply HPA
        run: |
          cat <<'EOF' > hpa.yaml
          apiVersion: autoscaling/v2
          kind: HorizontalPodAutoscaler
          metadata:
            name: iris-api-hpa
          spec:
            scaleTargetRef:
              apiVersion: apps/v1
              kind: Deployment
              name: iris-api
            minReplicas: 1
            maxReplicas: 3
            metrics:
              - type: Resource
                resource:
                  name: cpu
                  target:
                    type: Utilization
                    averageUtilization: 70
          EOF
          kubectl apply -f hpa.yaml

      # Install wrk and run stress tests
      - name: Install wrk & run stress tests
        run: |
          sudo apt-get update -y && sudo apt-get install -y wrk

          # Wait for service external IP
          EXTERNAL_IP=""
          for i in {1..30}; do
            EXTERNAL_IP=$(kubectl get svc iris-api -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [ -n "$EXTERNAL_IP" ]; then
              echo "Service ready at $EXTERNAL_IP"
              break
            fi
            echo "Waiting for service external IP..."
            sleep 10
          done
          if [ -z "$EXTERNAL_IP" ]; then
            echo "ERROR: Service did not get an external IP"
            exit 1
          fi
          echo "üåê Endpoint: http://$EXTERNAL_IP/predict"

          # Lua POST script for wrk
          cat <<'EOF' > post.lua
          wrk.method = "POST"
          wrk.body = '{"features": [5.1, 3.5, 1.4, 0.2]}'
          wrk.headers["Content-Type"] = "application/json"
          EOF

          # Run wrk stress tests
          echo "Running stress test: 1000 connections"
          wrk -t8 -c1000 -d30s -s post.lua http://$EXTERNAL_IP/predict

          echo "Running stress test: 1500 connections (observe scaling)"
          wrk -t8 -c1500 -d60s -s post.lua http://$EXTERNAL_IP/predict

          echo "Running stress test: 2000 connections (1 pod bottleneck)"
          kubectl delete hpa iris-api-hpa || true
          kubectl scale deployment iris-api --replicas=1
          wrk -t8 -c2000 -d45s -s post.lua http://$EXTERNAL_IP/predict

          # Show pod metrics
          kubectl top pods || echo "‚ö†Ô∏è Metrics server may not be installed"
