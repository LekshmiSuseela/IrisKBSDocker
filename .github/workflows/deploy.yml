name: CI/CD Pipeline for IRIS API

on:
  push:
    branches:
      - main

env:
  IMAGE_NAME: iris-api
  GAR_LOCATION: us-central1-docker.pkg.dev/mlops-474118/iris-api-repo/iris-api

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Start
      - name: âœ… Workflow started
        run: echo "ğŸš€ CI/CD triggered on branch ${{ github.ref }}"

      # Step 2: Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 3: Authenticate to Google Cloud
      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Step 4: Verify Authentication
      - name: ğŸ” Verify GCP Authentication
        run: |
          echo "Checking gcloud authentication..."
          gcloud auth list
          echo "Current GCP project config:"
          gcloud config list project

      # Step 5: Setup gcloud CLI
      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      # Step 6: Install GKE Auth Plugin
      - name: ğŸ§© Install GKE Auth Plugin
        run: |
          echo "ğŸ”§ Installing GKE gcloud auth plugin..."
          sudo apt-get update -y
          sudo apt-get install -y apt-transport-https ca-certificates gnupg
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | \
            sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
          curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | \
            sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update -y
          sudo apt-get install -y google-cloud-sdk-gke-gcloud-auth-plugin
          echo "âœ… Plugin installed successfully."

      # Step 7: Configure Docker
      - name: Configure Docker
        run: |
          echo "ğŸ”§ Configuring Docker to use Artifact Registry..."
          gcloud auth configure-docker ${{ secrets.GCP_REGION }}-docker.pkg.dev --quiet

      # Step 8: Build Docker Image
      - name: ğŸ—ï¸ Build Docker Image
        run: |
          echo "ğŸ› ï¸ Building Docker image..."
          docker build -t $GAR_LOCATION:${{ github.sha }} .

      # Step 9: Push Docker Image
      - name: ğŸš€ Push Docker Image
        run: |
          echo "ğŸ“¦ Pushing image to Artifact Registry..."
          docker push $GAR_LOCATION:${{ github.sha }}

      # Step 10: Connect to GKE
      - name: ğŸ”‘ Get GKE Credentials
        run: |
          echo "ğŸ”— Fetching GKE credentials..."
          gcloud container clusters get-credentials ${{ secrets.GKE_CLUSTER }} \
            --zone ${{ secrets.GKE_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }}

      # Step 11: Install Metrics Server
      - name: ğŸ–¥ï¸ Install Metrics Server
        run: |
          kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
          kubectl wait --for=condition=available --timeout=120s deployment/metrics-server -n kube-system


      # Step 12: Deploy to GKE
      - name: ğŸŒ Deploy to GKE
        run: |
          echo "ğŸš€ Updating deployment image..."
          kubectl set image deployment/iris-api iris-api=$GAR_LOCATION:${{ github.sha }} --namespace=default
          echo "ğŸ•’ Waiting for rollout to complete..."
          kubectl rollout status deployment/iris-api --namespace=default

      # Step 13: Post-deploy verification
      - name: âœ… Verify Deployment
        run: |
          echo "ğŸ” Checking running pods and services..."
          kubectl get pods --namespace=default
          kubectl get svc --namespace=default
          echo "ğŸ‰ Deployment successful!"

      # Step 14: ğŸ”¬ Install wrk for stress testing
      - name: ğŸ”§ Install wrk for stress testing
        run: |
          echo "ğŸ“¦ Installing wrk..."
          sudo apt-get update -y
          sudo apt-get install -y wrk
          echo "âœ… wrk installed successfully."

      # Step 15: ğŸ“ˆ Run stress test with 1000 concurrent requests
      - name: ğŸš€ Run wrk stress test (1000 concurrent)
        run: |
          echo "ğŸš€ Starting load test with wrk..."
          EXTERNAL_IP=$(kubectl get svc iris-api -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "ğŸŒ Testing endpoint: http://$EXTERNAL_IP/predict"

          # Create Lua script for POST request
          cat <<'EOF' > post.lua
          wrk.method = "POST"
          wrk.body   = '{"features": [5.1, 3.5, 1.4, 0.2]}'
          wrk.headers["Content-Type"] = "application/json"
          EOF

          # Run load test
          wrk -t8 -c1000 -d30s -s post.lua http://$EXTERNAL_IP/predict

      # Step 16: ğŸ§© Apply Horizontal Pod Autoscaler (HPA)
      - name: âš™ï¸ Apply HPA for autoscaling
        run: |
          echo "ğŸ“ˆ Applying Horizontal Pod Autoscaler..."
          cat <<'EOF' > hpa.yaml
          apiVersion: autoscaling/v2
          kind: HorizontalPodAutoscaler
          metadata:
            name: iris-api-hpa
          spec:
            scaleTargetRef:
              apiVersion: apps/v1
              kind: Deployment
              name: iris-api
            minReplicas: 1
            maxReplicas: 3
            metrics:
              - type: Resource
                resource:
                  name: cpu
                  target:
                    type: Utilization
                    averageUtilization: 70
          EOF

          kubectl apply -f hpa.yaml
          echo "âœ… HPA applied successfully."
          kubectl get hpa

      # Step 17: ğŸ” Observe scaling behavior
      - name: ğŸ” Observe scaling under load
        run: |
          echo "ğŸ§ª Running load test to trigger scaling..."
          EXTERNAL_IP=$(kubectl get svc iris-api -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "ğŸŒ Testing endpoint: http://$EXTERNAL_IP/predict"

          # Run longer stress test to trigger autoscaling
          wrk -t8 -c1500 -d60s -s post.lua http://$EXTERNAL_IP/predict

          echo "ğŸ“Š Current pod and HPA status:"
          kubectl get hpa
          kubectl get pods -o wide

      # Step 18: ğŸ§± Bottleneck analysis (when scaling disabled)
      - name: ğŸ§± Stress test with fixed 1 pod (bottleneck observation)
        run: |
          echo "ğŸš« Restricting autoscaling to 1 pod..."
          kubectl delete hpa iris-api-hpa || true
          kubectl scale deployment iris-api --replicas=1

          echo "ğŸš€ Running stress test with 2000 concurrent requests..."
          EXTERNAL_IP=$(kubectl get svc iris-api -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          wrk -t8 -c2000 -d45s -s post.lua http://$EXTERNAL_IP/predict

          echo "ğŸ“Š Checking resource usage:"
          kubectl top pods || echo "âš ï¸ Metrics server may not be installed"

